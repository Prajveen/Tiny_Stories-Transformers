{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datasets import load_dataset\n",
    "import sentencepiece as spm\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_inputs_and_labels(df):\n",
    "    inputs = []\n",
    "    labels = []\n",
    "\n",
    "    for index, row in df.iterrows():\n",
    "        text = row['text']\n",
    "        tokens = text.split()  # Tokenize the text by splitting on whitespace\n",
    "\n",
    "        # Generate input by adding start of sentence token at the beginning\n",
    "        input_sequence = ['<sos>'] + tokens\n",
    "\n",
    "        # Generate label by adding end of sentence token at the end\n",
    "        label_sequence = tokens + ['</sos>']\n",
    "\n",
    "        inputs.append(input_sequence)\n",
    "        labels.append(label_sequence)\n",
    "\n",
    "    return inputs, labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_json('train_data.json', lines=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One day, a little girl named Lily found a need...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Once upon a time, there was a little car named...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>One day, a little fish named Fin was swimming ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Once upon a time, in a land full of trees, the...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Once upon a time, there was a little girl name...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  One day, a little girl named Lily found a need...\n",
       "1  Once upon a time, there was a little car named...\n",
       "2  One day, a little fish named Fin was swimming ...\n",
       "3  Once upon a time, in a land full of trees, the...\n",
       "4  Once upon a time, there was a little girl name..."
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One day, a little girl named Lily found a need...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  One day, a little girl named Lily found a need..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = train_df[:1]\n",
    "train_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs, labels = generate_inputs_and_labels(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: ['<sos>', 'One', 'day,', 'a', 'little'] ... ['had', 'shared', 'and', 'worked', 'together.']\n",
      "Label: ['One', 'day,', 'a', 'little', 'girl'] ... ['shared', 'and', 'worked', 'together.', '</sos>']\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Print first 5 samples\n",
    "for i in range(min(5, len(inputs))):\n",
    "    print(\"Input:\", inputs[i][:5], \"...\", inputs[i][-5:])\n",
    "    print(\"Label:\", labels[i][:5], \"...\", labels[i][-5:])\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('small_m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Input: ['▁', '<', 'so', 's', '>', '▁one', '▁day', ',', '▁a', '▁little', '▁girl', '▁name', 'd', '▁lily', '▁found', '▁a', '▁needle', '▁in', '▁her', '▁room', '.', '▁she', '▁knew', '▁it', '▁was', '▁difficult', '▁to', '▁play', '▁with', '▁it', '▁', 'because', '▁it', '▁was', '▁sharp', '.', '▁lily', '▁wanted', '▁to', '▁share', '▁the', '▁needle', '▁with', '▁her', '▁mom', ',', '▁so', '▁she', '▁could', '▁sew', '▁a', '▁button', '▁on', '▁her', '▁shirt', '.', '▁lily', '▁went', '▁to', '▁her', '▁mom', '▁and', '▁said', ',', '▁\"', 'mom', ',', '▁i', '▁found', '▁this', '▁needle', '.', '▁can', '▁you', '▁share', '▁it', '▁with', '▁me', '▁and', '▁sew', '▁my', '▁shirt', '?\"', '▁her', '▁mom', '▁smiled', '▁and', '▁said', ',', '▁\"', 'yes', ',', '▁lily', ',', '▁we', '▁can', '▁share', '▁the', '▁needle', '▁and', '▁fix', '▁your', '▁shirt', '.\"', '▁together', ',', '▁they', '▁shared', '▁the', '▁needle', '▁and', '▁sew', 'ed', '▁the', '▁button', '▁on', '▁lily', \"'\", 's', '▁shirt', '.', '▁it', '▁was', '▁not', '▁difficult', '▁for', '▁them', '▁', 'because', '▁they', '▁were', '▁sharing', '▁and', '▁helping', '▁each', '▁other', '.', '▁after', '▁they', '▁finished', ',', '▁lily', '▁thank', 'ed', '▁her', '▁mom', '▁for', '▁sharing', '▁the', '▁needle', '▁and', '▁fix', 'ing', '▁her', '▁shirt', '.', '▁they', '▁both', '▁felt', '▁happy', '▁', 'because', '▁they', '▁had', '▁shared', '▁and', '▁worked', '▁together', '.']\n",
      "Tokenized Label: ['▁one', '▁day', ',', '▁a', '▁little', '▁girl', '▁name', 'd', '▁lily', '▁found', '▁a', '▁needle', '▁in', '▁her', '▁room', '.', '▁she', '▁knew', '▁it', '▁was', '▁difficult', '▁to', '▁play', '▁with', '▁it', '▁', 'because', '▁it', '▁was', '▁sharp', '.', '▁lily', '▁wanted', '▁to', '▁share', '▁the', '▁needle', '▁with', '▁her', '▁mom', ',', '▁so', '▁she', '▁could', '▁sew', '▁a', '▁button', '▁on', '▁her', '▁shirt', '.', '▁lily', '▁went', '▁to', '▁her', '▁mom', '▁and', '▁said', ',', '▁\"', 'mom', ',', '▁i', '▁found', '▁this', '▁needle', '.', '▁can', '▁you', '▁share', '▁it', '▁with', '▁me', '▁and', '▁sew', '▁my', '▁shirt', '?\"', '▁her', '▁mom', '▁smiled', '▁and', '▁said', ',', '▁\"', 'yes', ',', '▁lily', ',', '▁we', '▁can', '▁share', '▁the', '▁needle', '▁and', '▁fix', '▁your', '▁shirt', '.\"', '▁together', ',', '▁they', '▁shared', '▁the', '▁needle', '▁and', '▁sew', 'ed', '▁the', '▁button', '▁on', '▁lily', \"'\", 's', '▁shirt', '.', '▁it', '▁was', '▁not', '▁difficult', '▁for', '▁them', '▁', 'because', '▁they', '▁were', '▁sharing', '▁and', '▁helping', '▁each', '▁other', '.', '▁after', '▁they', '▁finished', ',', '▁lily', '▁thank', 'ed', '▁her', '▁mom', '▁for', '▁sharing', '▁the', '▁needle', '▁and', '▁fix', 'ing', '▁her', '▁shirt', '.', '▁they', '▁both', '▁felt', '▁happy', '▁', 'because', '▁they', '▁had', '▁shared', '▁and', '▁worked', '▁together', '.', '▁', '</', 'so', 's', '>']\n"
     ]
    }
   ],
   "source": [
    "# Convert input and label sequences to strings\n",
    "input_strings = [' '.join(sequence) for sequence in inputs]\n",
    "label_strings = [' '.join(sequence) for sequence in labels]\n",
    "\n",
    "# Tokenize input and label strings\n",
    "tokenized_inputs = [sp.encode_as_pieces(sequence) for sequence in input_strings]\n",
    "tokenized_labels = [sp.encode_as_pieces(sequence) for sequence in label_strings]\n",
    "\n",
    "# Print tokenized input and label sequences\n",
    "for i in range(len(inputs)):\n",
    "    print(\"Tokenized Input:\", tokenized_inputs[i])\n",
    "    print(\"Tokenized Label:\", tokenized_labels[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input Token IDs: [[[], [19, 0], [23], [298], [19, 0], [19, 38], [19, 28], [19, 6], [19, 8], [19, 37], [19, 53], [19, 86], [1233], [19, 31], [19, 119], [19, 8], [19, 1614], [19, 21], [19, 14], [19, 198], [19, 3], [19, 11], [19, 185], [19, 12], [19, 9], [19, 1455], [19, 7], [19, 54], [19, 24], [19, 12], [], [19, 230], [19, 12], [19, 9], [19, 1316], [19, 3], [19, 31], [19, 59], [19, 7], [19, 259], [19, 4], [19, 1614], [19, 24], [19, 14], [19, 43], [19, 6], [19, 23], [19, 11], [19, 94], [19, 2599], [19, 8], [19, 1293], [19, 32], [19, 14], [19, 802], [19, 3], [19, 31], [19, 68], [19, 7], [19, 14], [19, 43], [19, 5], [19, 18], [19, 6], [19, 16], [43], [19, 6], [19, 49], [19, 119], [19, 149], [19, 1614], [19, 3], [19, 66], [19, 25], [19, 259], [19, 12], [19, 24], [19, 145], [19, 5], [19, 2599], [19, 140], [19, 802], [19, 82], [19, 14], [19, 43], [19, 76], [19, 5], [19, 18], [19, 6], [19, 16], [542], [19, 6], [19, 31], [19, 6], [19, 96], [19, 66], [19, 259], [19, 4], [19, 1614], [19, 5], [19, 524], [19, 129], [19, 802], [19, 46], [19, 104], [19, 6], [19, 13], [19, 678], [19, 4], [19, 1614], [19, 5], [19, 2599], [19, 20], [19, 4], [19, 1293], [19, 32], [19, 31], [19, 17], [298], [19, 802], [19, 3], [19, 12], [19, 9], [19, 60], [19, 1455], [19, 36], [19, 64], [], [19, 230], [19, 13], [19, 50], [19, 1901], [19, 5], [19, 820], [19, 183], [19, 125], [19, 3], [19, 167], [19, 13], [19, 589], [19, 6], [19, 31], [19, 146], [19, 20], [19, 14], [19, 43], [19, 36], [19, 1901], [19, 4], [19, 1614], [19, 5], [19, 524], [19, 55], [19, 14], [19, 802], [19, 3], [19, 13], [19, 261], [19, 90], [19, 44], [], [19, 230], [19, 13], [19, 29], [19, 678], [19, 5], [19, 521], [19, 104], [19, 3]]]\n",
      "Label Token IDs: [[[19, 38], [19, 28], [19, 6], [19, 8], [19, 37], [19, 53], [19, 86], [1233], [19, 31], [19, 119], [19, 8], [19, 1614], [19, 21], [19, 14], [19, 198], [19, 3], [19, 11], [19, 185], [19, 12], [19, 9], [19, 1455], [19, 7], [19, 54], [19, 24], [19, 12], [], [19, 230], [19, 12], [19, 9], [19, 1316], [19, 3], [19, 31], [19, 59], [19, 7], [19, 259], [19, 4], [19, 1614], [19, 24], [19, 14], [19, 43], [19, 6], [19, 23], [19, 11], [19, 94], [19, 2599], [19, 8], [19, 1293], [19, 32], [19, 14], [19, 802], [19, 3], [19, 31], [19, 68], [19, 7], [19, 14], [19, 43], [19, 5], [19, 18], [19, 6], [19, 16], [43], [19, 6], [19, 49], [19, 119], [19, 149], [19, 1614], [19, 3], [19, 66], [19, 25], [19, 259], [19, 12], [19, 24], [19, 145], [19, 5], [19, 2599], [19, 140], [19, 802], [19, 82], [19, 14], [19, 43], [19, 76], [19, 5], [19, 18], [19, 6], [19, 16], [542], [19, 6], [19, 31], [19, 6], [19, 96], [19, 66], [19, 259], [19, 4], [19, 1614], [19, 5], [19, 524], [19, 129], [19, 802], [19, 46], [19, 104], [19, 6], [19, 13], [19, 678], [19, 4], [19, 1614], [19, 5], [19, 2599], [19, 20], [19, 4], [19, 1293], [19, 32], [19, 31], [19, 17], [298], [19, 802], [19, 3], [19, 12], [19, 9], [19, 60], [19, 1455], [19, 36], [19, 64], [], [19, 230], [19, 13], [19, 50], [19, 1901], [19, 5], [19, 820], [19, 183], [19, 125], [19, 3], [19, 167], [19, 13], [19, 589], [19, 6], [19, 31], [19, 146], [19, 20], [19, 14], [19, 43], [19, 36], [19, 1901], [19, 4], [19, 1614], [19, 5], [19, 524], [19, 55], [19, 14], [19, 802], [19, 3], [19, 13], [19, 261], [19, 90], [19, 44], [], [19, 230], [19, 13], [19, 29], [19, 678], [19, 5], [19, 521], [19, 104], [19, 3], [], [19, 0], [23], [298], [19, 0]]]\n"
     ]
    }
   ],
   "source": [
    "# Convert tokenized sequences to IDs\n",
    "input_ids = [sp.encode_as_ids(sequence) for sequence in tokenized_inputs]\n",
    "label_ids = [sp.encode_as_ids(sequence) for sequence in tokenized_labels]\n",
    "\n",
    "# Print token IDs\n",
    "print(\"Input Token IDs:\", input_ids)\n",
    "print(\"Label Token IDs:\", label_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
