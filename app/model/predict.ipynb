{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/beesamprajveenkumar/miniconda3/lib/python3.12/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from transformer import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "tgt_vocab_size = 5000\n",
    "d_model = 256\n",
    "num_heads = 4\n",
    "num_layers = 4\n",
    "d_ff = 512\n",
    "max_seq_length = 100\n",
    "dropout = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Transformer(\n",
       "  (decoder_embedding): Embedding(5000, 256)\n",
       "  (positional_encoding): PositionalEncoding()\n",
       "  (decoder_layers): ModuleList(\n",
       "    (0-3): 4 x DecoderLayer(\n",
       "      (self_attn): MultiHeadAttention(\n",
       "        (W_q): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (W_k): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (W_v): Linear(in_features=256, out_features=256, bias=True)\n",
       "        (W_o): Linear(in_features=256, out_features=256, bias=True)\n",
       "      )\n",
       "      (feed_forward): PositionWiseFeedForward(\n",
       "        (fc1): Linear(in_features=256, out_features=512, bias=True)\n",
       "        (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
       "        (relu): ReLU()\n",
       "      )\n",
       "      (norm1): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (fc): Linear(in_features=256, out_features=5000, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the trained model\n",
    "model = Transformer(tgt_vocab_size, d_model, num_heads, num_layers, d_ff, max_seq_length, dropout)\n",
    "model.load_state_dict(torch.load(\"/Users/beesamprajveenkumar/Documents/Projects/MLX/Tiny_Stories-Transformers/app/v2.pth\"))\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Example usage\n",
    "sp = spm.SentencePieceProcessor()\n",
    "sp.load('/Users/beesamprajveenkumar/Documents/Projects/MLX/Tiny_Stories-Transformers/app/small_m.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated sequence: lily! the little girl never saw a little girl. she wanted to play with her mom and said she had a lot of fun. the little girl was so excited to go on a special place. she wanted to get a big, but the little girl couldn't get the little girl. she said, \"i can you have to my favorite toy. i can we can we can we can we can we can we can we can we can we can we can we can we go?\" the\n"
     ]
    }
   ],
   "source": [
    "def word_to_token_id(word, sp_model):\n",
    "    # Convert word to token ID using SentencePiece\n",
    "    return sp_model.piece_to_id(word)\n",
    "\n",
    "def generate_text(starting_word, max_length):\n",
    "    \n",
    "    ending_word = \"</sos>\"\n",
    "    # Convert starting and ending words to token IDs\n",
    "    starting_token_id = word_to_token_id(starting_word, sp)\n",
    "    if starting_token_id is None:\n",
    "        raise ValueError(f\"Starting word '{starting_word}' not found in vocabulary.\")\n",
    "    \n",
    "    ending_token_id = word_to_token_id(ending_word, sp)\n",
    "    if ending_token_id is None:\n",
    "        raise ValueError(f\"Ending word '{ending_word}' not found in vocabulary.\")\n",
    "    \n",
    "    \n",
    "    generated_sequence = [starting_token_id]\n",
    "    with torch.no_grad():\n",
    "        for _ in range(max_length):\n",
    "            input_tensor = torch.tensor([generated_sequence])\n",
    "            output = model(input_tensor)\n",
    "            predicted_token = output.argmax(-1)[:,-1].item()\n",
    "            generated_sequence.append(predicted_token)\n",
    "            if predicted_token == ending_token_id:\n",
    "                break\n",
    "            \n",
    "    # Convert token IDs to words using SentencePiece\n",
    "    generated_text = sp.decode_ids(generated_sequence)\n",
    "    return generated_text\n",
    "\n",
    "# Example usage:\n",
    "starting_word = \"lily\"\n",
    "max_length = 100\n",
    "generated_sequence = generate_text(starting_word, max_length)\n",
    "print(\"Generated sequence:\", generated_sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
